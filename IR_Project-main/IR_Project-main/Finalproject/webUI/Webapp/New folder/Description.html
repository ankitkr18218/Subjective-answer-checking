<!DOCTYPE html>
<html>
	
	
		
		<!--tabel theree-->
		<table width="100%">
			<tr>
				<td width="75%">
					<h2>About</h2>
		<p>
			Traditional answer evaluation ie. manual checking of answers takes a lot of time and energy. However, till now objective type questions can be evaluated using computers very efficiently but when it comes to theoretical evaluation of answers there does not exist a platform for checking the answers very precisely, and efficiently. so always there is a need for a checker to check the answers manually, which takes a lot of effort and time, and sometimes he/she has to provide the feedback as well which would again take a lot of effort and analysis. 
<br>
Hence, we propose a system that evaluates the assessment copies automatically according to the rubric set by the checker for every type of question(subjective and objective) and also for multiple types of copies like pdf, scanned pdf.  our system would also give feedback over every question in a sheet generated for each student.<br>	

<h3>How to use the this system</h3>

<li><strong>Step-1:</strong>Firstly we need to upload the folder of the students</li>
<li><strong>Step-2:</strong>Then we need to upload the rubric for the evaluation</li>
<li><strong>Step-3:</strong>Then in the bakend evaluation get done </li>
<li><strong>Step-4:</strong>Upload the report </li>
<li><strong>Step-5:</strong>Send to the TA or TA can send to the Student through mail</li>

<!-- <br>
<li>Our system could reduce lots of human time, power and money, which could be utilized in a better place.</li><br>
<li>Our system would also accept the handwritten scanned type file which could be  submitted by students.</li>
<br>
<li>Our system provides feedback over every solution to the student in a .csv file, and also collective feedback of the whole class for each question in the form of a pie chart and histogram to the checker.</li>
<br>
<li>Our system is also supposed to provide the partial marking or binary marking option, which could be opted by the checker.</li> -->
.<br>
			
				
		 </p>
		 <h2>Literature review</h2>
		 <p>
<dt><strong>Answer Evaluation Using Machine Learning:-</strong></dt>
For using this application we have to scan the answer to a question, then the system will automatically generate the keyword using OCR technique. Based on keywords written in the answer and the keywords in the dataset, the application provides marks.[1]
<dt><strong>Limitation:-</strong></dt>
This model can not evaluate the handwritten text from the answers. It can only check the printed text from the image of answers.
It does not include a feedback feature as well.<br>
<br>

<dt><strong>ONLINE SUBJECTIVE ANSWER CHECKER:-</strong></dt>
Answer selected by the student (String1) is compared with the answer stored in the database( String2) provided by the checker. If String1= String2 then score=+1 or else score=0. After processing the results of the test into the database the results are displayed to the student.[2]
<dt><strong>Limitation:-</strong></dt>
This system is not efficient but it is less time consuming and still lacks the feature of extracting the handwritten text from the image i.e. this model checks only digital or printed text.
It does not include a feedback feature as well.<br>
<br>

<dt><strong>NATURAL LANGUAGE PROCESSING AND ARTIFICIAL NEURAL NETWORKS</strong></dt>
Once the student has submitted the answer, this system will automatically calculate the result using two algorithms of NLP (Natural Language Processing) and ANN (Artificial Neural Network). Here this model uses Artificial Neural Networks algorithm for the normal answer comparison and evaluates the same answer using Natural language processing [NLP] algorithm for grammar mistakes and stores the marks in the student database. Some basic linguistic analysis is performed in a natural language parser and is respectively used to perform POS tagging of the student’s answer text. After linguistic analysis, the student’s answer text is processed by the artificial neural networks algorithm; it will compare the student’s answer text with the answer provided by checker and with keywords. The result of each process is calculated using a “marks calculator” to compute the total marks obtained by the student for his/her answer and finally compares both marks and provides a final result.[3]
<br> 
<dt><strong>Limitation:-</strong></dt>
This model is still in the phase of development for recognition of handwritten text using deep learning methods i.e. it is still not implemented. 
<br>
<br>

<dt><strong>Automated Answering for Subjective Examination [4]</strong></dt>
This is a nice platform for answer checking. It has a feature which allows more than one possible answer to the question and provides marks for any possible answer.
	
<dt><strong>Limitation:-</strong></dt> Although it was a good platform But, it does not provide feedback on each answer and also does not work over handwritten text.<br>

<br>


<strong>AI Answer Verifier[5]</strong></dt>
It is a good platform here, instructors only need to upload the answer sheets and rubric. Also, he can make a rubric there as well.
<dt><strong>Limitation:-</strong></dt> It was friendly for the instructor but if an answer sheet has many types of questions and if some has partial marking and some has binary marking then this model won’t work perfectly.<br>
<br>
		 	<ul>
		 		<li>Home</li>
		 		<li>Description</li>
		 		<li>Upload Folder</li>
		 		<li>Upload Rubric</li>
		 		<li>Evaluate</li>
		 		<li>Upload Report</li>
		 		<li>Send</li>
		 		<li>Login</li>
		 		<li>Contact Us</li>
		 		
		 	</ul>
		 </p>

		




				



		 		<dt><strong>Description</strong></dt>
		 		<dd>Here we given the brief How to use the proposed system and what exatly doing</dd>
		 		<dt><strong>Upload Folder</strong></dt>
		 		<dd>Here evaluator need to upload the folder of students </dd>
		 		<dt><strong>Upload Rubric</strong></dt>
		 		<dd>Here the rubric need to upload for the evaluation process</dd>
		 		<dt><strong>Report</strong></dt>
		 		<dd>This is the contact option of the head of the family.</dd>
		 		<dt><strong>Login</strong></dt>
		 		<dd>This is the contact option of the head of the family.</dd>
		 		<dt><strong>Contact Us</strong></dt>
		 		<dd>This is the contact option of the head of the family.</dd>
		 		
		 <!-- 	</dl> -->

		 	
		 </p>
		 <a href="#1">click here to go up</a>
				<!-- 	
				</td>
				<td width="25%" align="center">
					
					<p>
						<h1><strong><mark>Imopratance Of Online Evaluation System</mark></strong></h1>
						<iframe width="560" height="315" src="https://www.youtube.com/embed/pbS6jPu-oXs" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
						<a href="https://www.google.com/"><br>Search here anything from internet</a>
					</p>
				</td> -->
			</tr>
			
		</table>
			
		
		

	</body>
</html>